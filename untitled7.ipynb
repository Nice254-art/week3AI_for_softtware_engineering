{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üß† AI Foundations Assessment  \n",
        "### üèÖ *Part 1: Theoretical Understanding (40%)*  \n",
        "\n",
        "---\n",
        "\n",
        "## üîπ Q1: Explain the primary differences between TensorFlow and PyTorch. When would you choose one over the other?\n",
        "\n",
        "### ‚úÖ **Answer:**\n",
        "\n",
        "TensorFlow and PyTorch are both **deep learning frameworks** used to build and train neural networks, but they differ in **design philosophy**, **syntax**, and **user experience**.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚öôÔ∏è 1. Computation Graphs\n",
        "\n",
        "- **TensorFlow:**  \n",
        "  Uses a **static computation graph** (especially in older versions like TF 1.x).  \n",
        "  This means you must **define the entire model first** before running it.  \n",
        "  - ‚úÖ *Advantage:* Highly optimized for **deployment** and **scalability**.  \n",
        "  - ‚ö†Ô∏è *Disadvantage:* Less intuitive for debugging.\n",
        "\n",
        "- **PyTorch:**  \n",
        "  Uses a **dynamic computation graph** ‚Äî built **on the fly as code runs**.  \n",
        "  - ‚úÖ *Advantage:* Great for **experimentation**, **debugging**, and **research**.  \n",
        "  - ‚ö†Ô∏è *Disadvantage:* Historically less optimized for deployment (though PyTorch 2.0 improved this).\n",
        "\n",
        "---\n",
        "\n",
        "### üß© 2. Syntax and Coding Style\n",
        "\n",
        "- **TensorFlow:**  \n",
        "  Uses a more **declarative syntax** ‚Äî you \"declare\" operations first.  \n",
        "  Often paired with **Keras** for ease of model creation.  \n",
        "\n",
        "- **PyTorch:**  \n",
        "  Uses **imperative programming**, similar to normal Python, making it intuitive and pythonic.\n",
        "\n",
        "---\n",
        "\n",
        "### üåê 3. Ecosystem and Deployment\n",
        "\n",
        "| Feature | TensorFlow | PyTorch |\n",
        "|----------|-------------|----------|\n",
        "| Deployment Tools | TensorFlow Serving, Lite, JS | TorchServe, ONNX |\n",
        "| Community | Backed by Google, strong industry support | Preferred by academic researchers |\n",
        "| Platforms | Web, mobile, edge devices | Research, experimentation |\n",
        "\n",
        "---\n",
        "\n",
        "### üß≠ 4. When to Choose Each\n",
        "\n",
        "| Use Case | Best Framework |\n",
        "|-----------|----------------|\n",
        "| Academic research, prototyping, experimentation | üß† **PyTorch** |\n",
        "| Production deployment, scalability, cross-platform apps | ‚öôÔ∏è **TensorFlow** |\n",
        "| Beginners who prefer simplicity | üéØ **Keras (on TensorFlow)** |\n",
        "\n",
        "---\n",
        "\n",
        "### üí° **Example Summary**\n",
        "\n",
        "> ‚ÄúIf I were developing a new neural network architecture for research, I‚Äôd use **PyTorch** for its flexibility and intuitive debugging.  \n",
        "> But if I were building a scalable image classification system for a company product, I‚Äôd choose **TensorFlow** for its strong deployment ecosystem.‚Äù\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ Q2: Describe two use cases for Jupyter Notebooks in AI development.\n",
        "\n",
        "### ‚úÖ **Answer:**\n",
        "\n",
        "Jupyter Notebooks are an **interactive environment** for combining **code, visuals, and explanations** ‚Äî perfect for AI and data science.\n",
        "\n",
        "---\n",
        "\n",
        "### üìä **Use Case 1: Data Exploration and Preprocessing**\n",
        "\n",
        "- Allows **step-by-step** exploration and cleaning of datasets.  \n",
        "- Integrates visualization tools like **Matplotlib**, **Seaborn**, and **Plotly**.  \n",
        "- Example: Checking for missing values, plotting data distributions.\n",
        "\n",
        "> üß† *Why useful:* Encourages **experimentation** without rerunning full scripts.\n",
        "\n",
        "---\n",
        "\n",
        "### ü§ñ **Use Case 2: Model Training and Documentation**\n",
        "\n",
        "- Train machine learning models incrementally (e.g., Scikit-learn, TensorFlow).  \n",
        "- Add **Markdown explanations** between code cells.  \n",
        "- Great for teaching, sharing, and collaboration.\n",
        "\n",
        "> üß© *Why useful:* Combines **code + explanation + results** ‚Üí reproducibility and clarity.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úçÔ∏è **Model Answer Summary**\n",
        "\n",
        "> ‚ÄúJupyter Notebooks enable **interactive data exploration** and **stepwise model training**.  \n",
        "> They help developers visualize results and document experiments for better reproducibility and communication.‚Äù\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ Q3: How does spaCy enhance NLP tasks compared to basic Python string operations?\n",
        "\n",
        "### ‚úÖ **Answer:**\n",
        "\n",
        "While basic Python string operations can handle simple text manipulation, **spaCy** provides **machine learning-powered linguistic analysis**, making it ideal for **advanced NLP tasks**.\n",
        "\n",
        "---\n",
        "\n",
        "### üß± **Key Differences**\n",
        "\n",
        "| Feature | Basic Python (`str` ops) | spaCy |\n",
        "|----------|--------------------------|--------|\n",
        "| Tokenization | Manual split by spaces | Smart tokenization (handles contractions, punctuation) |\n",
        "| Part-of-Speech Tagging | ‚ùå Not available | ‚úÖ Identifies nouns, verbs, adjectives |\n",
        "| Named Entity Recognition | ‚ùå Not available | ‚úÖ Detects names, locations, organizations |\n",
        "| Lemmatization | Manual | Built-in (e.g., ‚Äúrunning‚Äù ‚Üí ‚Äúrun‚Äù) |\n",
        "| Dependency Parsing | ‚ùå Not possible | ‚úÖ Analyzes grammatical structure |\n",
        "\n",
        "---\n",
        "\n",
        "### üíª **Example Code**\n",
        "\n",
        "```python\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
        "\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)\n"
      ],
      "metadata": {
        "id": "jUpoCwqg3fyy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß† Part 2: Practical Implementation (50%)\n",
        "\n",
        "üß© Task 1: Classical Machine Learning with Scikit-learn\n",
        "Goal\n",
        "\n",
        "Train a Decision Tree Classifier using the Iris dataset to predict flower species.\n",
        "\n",
        "Steps Overview\n",
        "\n",
        "Load and explore the dataset\n",
        "\n",
        "Handle missing values and encode categorical labels\n",
        "\n",
        "Split data into training and testing sets\n",
        "\n",
        "Train a Decision Tree model\n",
        "\n",
        "Evaluate using accuracy, precision, and recall\n",
        "\n",
        "üìù Explanation\n",
        "\n",
        "Decision Trees split data into branches based on feature values to make predictions.\n",
        "\n",
        "Accuracy tells us how many total predictions were correct.\n",
        "\n",
        "Precision measures correctness among positive predictions.\n",
        "\n",
        "Recall shows how well the model captures all relevant instances.\n",
        "\n",
        "üí° Expected Outcome: You should get accuracy close to 0.95‚Äì1.00 since the Iris dataset is simple and well-structured."
      ],
      "metadata": {
        "id": "3KekiGVm4pMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================\n",
        "# TASK 1: IRIS SPECIES CLASSIFICATION\n",
        "# =====================================\n",
        "\n",
        "# 1Ô∏è‚É£ Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# 2Ô∏è‚É£ Load dataset\n",
        "iris = load_iris()\n",
        "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "y = pd.Series(iris.target, name=\"species\")\n",
        "\n",
        "# 3Ô∏è‚É£ Introduce preprocessing step (handling missing values)\n",
        "# For demonstration, let's assume some missing values exist.\n",
        "X.iloc[0, 0] = np.nan  # simulate a missing value\n",
        "\n",
        "# Replace missing values with column mean\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X = pd.DataFrame(imputer.fit_transform(X), columns=iris.feature_names)\n",
        "\n",
        "# 4Ô∏è‚É£ Encode labels (in this dataset labels are already numeric, but this step is good practice)\n",
        "encoder = LabelEncoder()\n",
        "y_encoded = encoder.fit_transform(y)\n",
        "\n",
        "# 5Ô∏è‚É£ Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# 6Ô∏è‚É£ Initialize and train the Decision Tree Classifier\n",
        "model = DecisionTreeClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 7Ô∏è‚É£ Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 8Ô∏è‚É£ Evaluate performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='macro')\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "\n",
        "print(\"üéØ Model Evaluation:\")\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(\"\\nDetailed Report:\\n\", classification_report(y_test, y_pred, target_names=iris.target_names))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClhoV2TC0UdR",
        "outputId": "a113b09c-b20a-492f-acbe-9ddd03a9e4c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéØ Model Evaluation:\n",
            "Accuracy: 1.00\n",
            "Precision: 1.00\n",
            "Recall: 1.00\n",
            "\n",
            "Detailed Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        10\n",
            "  versicolor       1.00      1.00      1.00         9\n",
            "   virginica       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ü§ñ Task 2: Deep Learning with TensorFlow (CNN on MNIST)\n",
        "Goal\n",
        "\n",
        "Train a Convolutional Neural Network (CNN) to classify handwritten digits (0‚Äì9) from the MNIST dataset.\n",
        "\n",
        "Steps Overview\n",
        "\n",
        "Load and normalize the MNIST dataset\n",
        "\n",
        "Build a CNN model (Conv2D ‚Üí MaxPooling ‚Üí Dense)\n",
        "\n",
        "Train for several epochs\n",
        "\n",
        "Evaluate test accuracy (>95%)\n",
        "\n",
        "Visualize predictions on 5 sample images\n",
        "\n",
        "üìù Explanation\n",
        "\n",
        "The CNN learns spatial patterns in images using filters and pooling.\n",
        "\n",
        "The softmax layer outputs probabilities for each digit (0‚Äì9).\n",
        "\n",
        "We expect test accuracy > 95%, showing strong generalization.\n",
        "\n",
        "The visualization confirms the model‚Äôs understanding of digit shapes.\n",
        "\n",
        "üí° Tip: Increasing epochs or using dropout can further improve performance."
      ],
      "metadata": {
        "id": "RUTOYy2s5bWK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "j30AR3t-sMCW",
        "outputId": "c912a431-9670-4ee2-d280-81049b10ebfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 20ms/step - accuracy: 0.8984 - loss: 0.3220 - val_accuracy: 0.9840 - val_loss: 0.0498\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 18ms/step - accuracy: 0.9830 - loss: 0.0544 - val_accuracy: 0.9895 - val_loss: 0.0324\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 18ms/step - accuracy: 0.9887 - loss: 0.0337 - val_accuracy: 0.9892 - val_loss: 0.0315\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 18ms/step - accuracy: 0.9919 - loss: 0.0253 - val_accuracy: 0.9882 - val_loss: 0.0400\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 18ms/step - accuracy: 0.9937 - loss: 0.0191 - val_accuracy: 0.9893 - val_loss: 0.0321\n",
            "313/313 - 2s - 6ms/step - accuracy: 0.9893 - loss: 0.0321\n",
            "\n",
            "‚úÖ Test Accuracy: 98.93%\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_01979ae8-2265-4f3a-bb2d-c186040055d2\", \"mnist_model.h5\", 1502296)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# =====================================\n",
        "# TASK 2: MNIST DIGIT CLASSIFICATION\n",
        "# =====================================\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# 1Ô∏è‚É£ Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# 2Ô∏è‚É£ Normalize pixel values (scale 0-255 ‚Üí 0-1)\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# 3Ô∏è‚É£ Reshape data for CNN input (batch, height, width, channels)\n",
        "x_train = x_train[..., np.newaxis]\n",
        "x_test = x_test[..., np.newaxis]\n",
        "\n",
        "# 4Ô∏è‚É£ Define CNN model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')  # 10 output classes (digits 0-9)\n",
        "])\n",
        "\n",
        "# 5Ô∏è‚É£ Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 6Ô∏è‚É£ Train the model\n",
        "history = model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
        "\n",
        "# 7Ô∏è‚É£ Evaluate on test data\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"\\n‚úÖ Test Accuracy: {test_acc*100:.2f}%\")\n",
        "\n",
        "# 8Ô∏è‚É£ Visualize 5 predictions\n",
        "predictions = model.predict(x_test[:5])\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "for i in range(5):\n",
        "    plt.subplot(1, 5, i+1)\n",
        "    plt.imshow(x_test[i].reshape(28,28), cmap='gray')\n",
        "    plt.title(f\"Pred: {np.argmax(predictions[i])}\\nTrue: {y_test[i]}\")\n",
        "    plt.axis('off')\n",
        "plt.show()\n",
        "model.save(\"mnist_model.h5\")\n",
        "\n",
        "# Download the model to your computer\n",
        "from google.colab import files\n",
        "files.download(\"mnist_model.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# (After training)\n",
        "model.save(\"mnist_model.h5\")\n",
        "\n",
        "# Download the model to your computer\n",
        "from google.colab import files\n",
        "files.download(\"mnist_model.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "9eYbNJvT77p0",
        "outputId": "c306050a-6202-4c73-8451-adba20f7190e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'DecisionTreeClassifier' object has no attribute 'save'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-95200270.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# (After training)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mnist_model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Download the model to your computer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DecisionTreeClassifier' object has no attribute 'save'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üí¨ Task 3: NLP with spaCy (NER + Sentiment Analysis)\n",
        "Goal\n",
        "\n",
        "Use spaCy to:\n",
        "\n",
        "Extract named entities like product names and brands from Amazon reviews\n",
        "\n",
        "Perform rule-based sentiment analysis (positive or negative)\n",
        "\n",
        "Steps Overview\n",
        "\n",
        "Load spaCy language model\n",
        "\n",
        "Extract named entities from text\n",
        "\n",
        "Define a simple sentiment analyzer\n",
        "\n",
        "Print results for each review\n",
        "\n",
        "üìù Explanation\n",
        "\n",
        "spaCy automatically detects entities (e.g., Apple, Sony, Dell) using its trained NLP model.\n",
        "\n",
        "The rule-based sentiment analyzer checks for known positive or negative words.\n",
        "\n",
        "You‚Äôll see extracted entities and an emotion label for each review.\n",
        "\n",
        "üí° Extension idea: Replace rule-based logic with a machine learning sentiment classifier for more accuracy."
      ],
      "metadata": {
        "id": "W6t2IV4K50IA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================\n",
        "# TASK 3: NLP WITH SPACY (NER + SENTIMENT)\n",
        "# =====================================\n",
        "\n",
        "import spacy\n",
        "\n",
        "# 1Ô∏è‚É£ Load spaCy model (English small)\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# 2Ô∏è‚É£ Example Amazon reviews\n",
        "reviews = [\n",
        "    \"I love my new Apple iPhone 14, the camera quality is amazing!\",\n",
        "    \"The Samsung TV stopped working after a week. Very disappointed!\",\n",
        "    \"Sony headphones are super comfortable and sound great.\",\n",
        "    \"The laptop bag from Lenovo is too small for my 16-inch laptop.\",\n",
        "]\n",
        "\n",
        "# 3Ô∏è‚É£ Named Entity Recognition (NER)\n",
        "for text in reviews:\n",
        "    doc = nlp(text)\n",
        "    print(f\"\\nüìù Review: {text}\")\n",
        "    print(\"üîç Named Entities:\")\n",
        "    for ent in doc.ents:\n",
        "        print(f\"  {ent.text} ‚Üí {ent.label_}\")\n",
        "\n",
        "# 4Ô∏è‚É£ Simple rule-based sentiment analysis\n",
        "def simple_sentiment(text):\n",
        "    text_lower = text.lower()\n",
        "    positive_words = [\"love\", \"amazing\", \"great\", \"excellent\", \"good\", \"happy\"]\n",
        "    negative_words = [\"bad\", \"disappointed\", \"terrible\", \"poor\", \"worst\", \"stopped\"]\n",
        "\n",
        "    pos = sum(word in text_lower for word in positive_words)\n",
        "    neg = sum(word in text_lower for word in negative_words)\n",
        "\n",
        "    if pos > neg:\n",
        "        return \"üòä Positive\"\n",
        "    elif neg > pos:\n",
        "        return \"üòû Negative\"\n",
        "    else:\n",
        "        return \"üòê Neutral\"\n",
        "\n",
        "# 5Ô∏è‚É£ Apply sentiment analysis\n",
        "for text in reviews:\n",
        "    sentiment = simple_sentiment(text)\n",
        "    print(f\"\\nReview: {text}\\nSentiment: {sentiment}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcvskh8jz9_8",
        "outputId": "2fcd16e5-9994-428b-ba49-3e449bedacb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìù Review: I love my new Apple iPhone 14, the camera quality is amazing!\n",
            "üîç Named Entities:\n",
            "  Apple ‚Üí ORG\n",
            "  14 ‚Üí DATE\n",
            "\n",
            "üìù Review: The Samsung TV stopped working after a week. Very disappointed!\n",
            "üîç Named Entities:\n",
            "  Samsung TV ‚Üí ORG\n",
            "  a week ‚Üí DATE\n",
            "\n",
            "üìù Review: Sony headphones are super comfortable and sound great.\n",
            "üîç Named Entities:\n",
            "  Sony ‚Üí ORG\n",
            "\n",
            "üìù Review: The laptop bag from Lenovo is too small for my 16-inch laptop.\n",
            "üîç Named Entities:\n",
            "  Lenovo ‚Üí ORG\n",
            "  16-inch ‚Üí QUANTITY\n",
            "\n",
            "Review: I love my new Apple iPhone 14, the camera quality is amazing!\n",
            "Sentiment: üòä Positive\n",
            "\n",
            "Review: The Samsung TV stopped working after a week. Very disappointed!\n",
            "Sentiment: üòû Negative\n",
            "\n",
            "Review: Sony headphones are super comfortable and sound great.\n",
            "Sentiment: üòä Positive\n",
            "\n",
            "Review: The laptop bag from Lenovo is too small for my 16-inch laptop.\n",
            "Sentiment: üòê Neutral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## ‚öñÔ∏è **Part 3: Ethics & Optimization (10%)**\n",
        "\n",
        "---\n",
        "\n",
        "### üß† **1. Ethical Considerations**\n",
        "\n",
        "#### **Question:**\n",
        "\n",
        "Identify potential biases in your MNIST or Amazon Reviews model.\n",
        "How could tools like **TensorFlow Fairness Indicators** or **spaCy‚Äôs rule-based systems** help mitigate these biases?\n",
        "\n",
        "---\n",
        "\n",
        "#### **Answer:**\n",
        "\n",
        "AI models often **reflect biases** found in their **training data**, leading to unfair or misleading outcomes. Let‚Äôs analyze both cases:\n",
        "\n",
        "---\n",
        "\n",
        "#### **üü¢ MNIST Model Bias**\n",
        "\n",
        "The **MNIST dataset** consists mostly of **handwritten digits from Western countries**, written in Latin numerals.\n",
        "\n",
        "**Potential Biases:**\n",
        "\n",
        "* The model might perform poorly on digits written by people with **different handwriting styles** (e.g., from other cultures or scripts).\n",
        "* It assumes that all digits are **28√ó28 grayscale**, ignoring real-world variation in size, color, or lighting.\n",
        "\n",
        "**How to Mitigate:**\n",
        "\n",
        "* Use **TensorFlow Fairness Indicators** to monitor accuracy across subgroups (e.g., different handwriting types).\n",
        "* **Augment the dataset** with digits from diverse handwriting datasets.\n",
        "* Apply **data normalization and fairness metrics** before deployment.\n",
        "\n",
        "---\n",
        "\n",
        "#### **üü£ Amazon Reviews (NLP) Model Bias**\n",
        "\n",
        "The **spaCy + rule-based sentiment analyzer** might misjudge tone due to:\n",
        "\n",
        "* Cultural differences in expressing sentiment (e.g., sarcasm, slang).\n",
        "* Unequal use of positive/negative words in product categories.\n",
        "* Lack of representation from certain groups of users or languages.\n",
        "\n",
        "**How to Mitigate:**\n",
        "\n",
        "* Use **spaCy‚Äôs rule-based matching** to build **custom lexicons** that account for context (e.g., ‚Äúsick‚Äù = positive in slang).\n",
        "* Collect more **balanced review samples** across demographics and regions.\n",
        "* Validate fairness using **human feedback loops** or **context-aware transformers** (e.g., BERT).\n",
        "\n",
        "---\n",
        "\n",
        "#### **‚úÖ Summary**\n",
        "\n",
        "> ‚ÄúEthical AI requires more than accuracy ‚Äî it needs fairness, representation, and context awareness.\n",
        "> Tools like TensorFlow Fairness Indicators and spaCy‚Äôs custom rules help detect and reduce bias by analyzing model performance across diverse user groups.‚Äù\n",
        "\n",
        "---\n",
        "\n",
        "### üß© **2. Troubleshooting Challenge**\n",
        "\n",
        "#### **Question:**\n",
        "\n",
        "A provided TensorFlow script has errors (dimension mismatches, incorrect loss functions). Debug and fix it.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Buggy Example Code**\n",
        "\n",
        "```python\n",
        "# ‚ùå Buggy TensorFlow Code\n",
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, input_shape=(28,28), activation='relu'),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "model.fit(x_train, y_train, epochs=3)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### **üîß Fixed Code with Explanations**\n",
        "\n",
        "```python\n",
        "# ‚úÖ Fixed TensorFlow Code (with explanations)\n",
        "import tensorflow as tf\n",
        "\n",
        "# 1Ô∏è‚É£ Load and preprocess data\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# 2Ô∏è‚É£ Add channel dimension for CNN input\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# 3Ô∏è‚É£ One-hot encoding is not required with sparse_categorical_crossentropy\n",
        "#    So we keep labels as integers (0-9)\n",
        "\n",
        "# 4Ô∏è‚É£ Define correct model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# 5Ô∏è‚É£ Compile with correct loss function for integer labels\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 6Ô∏è‚É£ Train model\n",
        "model.fit(x_train, y_train, epochs=3, validation_data=(x_test, y_test))\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### **üìù Explanation of Fixes**\n",
        "\n",
        "| Issue                     | Cause                                               | Fix                                            |\n",
        "| ------------------------- | --------------------------------------------------- | ---------------------------------------------- |\n",
        "| Input shape mismatch      | Dense layer expected 1D input, got 2D (28√ó28)       | Added Flatten/CNN layer with `(28,28,1)` input |\n",
        "| Wrong loss function       | Used `categorical_crossentropy` with integer labels | Changed to `sparse_categorical_crossentropy`   |\n",
        "| Unscaled images           | Pixel values were 0‚Äì255                             | Normalized to 0‚Äì1                              |\n",
        "| Missing output activation | Output layer lacked `softmax`                       | Added softmax for probabilities                |\n",
        "\n",
        "> ‚úÖ **Result:** Model now trains properly and reaches >95% accuracy without dimension or loss errors.\n",
        "\n",
        "---\n",
        "\n",
        "### üöÄ **Bonus Task (Extra 10%) ‚Äî Model Deployment**\n",
        "\n",
        "#### **Goal**\n",
        "\n",
        "Deploy your trained **MNIST classifier** as a **web app** using **Streamlit** or **Flask**.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Approach (Streamlit Example)**\n",
        "\n",
        "1. Save your trained TensorFlow model (`model.save(\"mnist_model.h5\")`)\n",
        "2. Create a `streamlit_app.py` file\n",
        "3. Build a simple interface where users can upload a handwritten digit image and get a prediction\n",
        "\n",
        "---\n",
        "\n",
        "#### **Example Code (Streamlit)**\n",
        "\n",
        "```python\n",
        "# üöÄ Streamlit MNIST App\n",
        "import streamlit as st\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Load trained model\n",
        "model = tf.keras.models.load_model(\"mnist_model.h5\")\n",
        "\n",
        "st.title(\"üßÆ Handwritten Digit Classifier\")\n",
        "st.write(\"Upload a grayscale image of a digit (0-9)\")\n",
        "\n",
        "uploaded = st.file_uploader(\"Choose an image...\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
        "\n",
        "if uploaded is not None:\n",
        "    img = Image.open(uploaded).convert(\"L\").resize((28,28))\n",
        "    img_array = np.array(img) / 255.0\n",
        "    img_array = img_array.reshape(1, 28, 28, 1)\n",
        "\n",
        "    prediction = np.argmax(model.predict(img_array))\n",
        "    st.image(img, caption=\"Uploaded Image\", use_column_width=True)\n",
        "    st.success(f\"Predicted Digit: {prediction}\")\n",
        "```\n",
        "\n",
        "To run locally:\n",
        "\n",
        "```bash\n",
        "streamlit run streamlit_app.py\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### **Expected Outcome**\n",
        "\n",
        "* User uploads an image (e.g., `3.png`)\n",
        "* App displays the digit and predicts the correct number\n",
        "* The interface looks clean and interactive\n",
        "\n",
        "> üí° **Tip:** You can host it on **Streamlit Cloud** or **Render** for a live demo and share your deployment link or screenshot.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ **End of Part 3 Summary**\n",
        "\n",
        "| Section                | Skill Demonstrated    | Key Takeaway                     |\n",
        "| ---------------------- | --------------------- | -------------------------------- |\n",
        "| Ethical Considerations | Responsible AI design | Fairness and bias mitigation     |\n",
        "| Debugging Challenge    | Problem-solving       | Correcting data/model mismatches |\n",
        "| Bonus Deployment       | Practical integration | End-to-end AI product lifecycle  |\n",
        "\n",
        "---\n",
        "\n",
        "this is a live demo for my steamlitapp https://mnist-app-app-konjakfcjuehprkf4fyui4.streamlit.app/\n"
      ],
      "metadata": {
        "id": "7HYqExSv6l0g"
      }
    }
  ]
}